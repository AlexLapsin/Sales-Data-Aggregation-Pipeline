# Project Structure

This document describes the organized structure of the Sales Data Aggregation Pipeline after professional reorganization.

## Directory Structure Overview

```
sales_data_aggregation_pipeline/
â”œâ”€â”€ ğŸ“ src/                          # Core application source code
â”œâ”€â”€ ğŸ“ orchestration/                # Workflow orchestration (Airflow, scripts)
â”œâ”€â”€ ğŸ“ infrastructure/               # Infrastructure as Code (Terraform, Docker)
â”œâ”€â”€ ğŸ“ config/                       # Centralized configuration management
â”œâ”€â”€ ğŸ“ tests/                        # Unified testing framework
â”œâ”€â”€ ğŸ“ docs/                         # Consolidated documentation
â”œâ”€â”€ ğŸ“ tools/                        # Development and operational tools
â”œâ”€â”€ ğŸ“ requirements/                 # Dependency management
â”œâ”€â”€ ğŸ“„ .env                          # Environment configuration (user's original)
â”œâ”€â”€ ğŸ“„ .env.example                  # Environment template
â”œâ”€â”€ ğŸ“„ README.md                     # Main project documentation
â”œâ”€â”€ ğŸ“„ pyproject.toml                # Modern Python project configuration
â”œâ”€â”€ ğŸ“„ requirements.txt              # Main requirements file
â””â”€â”€ ğŸ“„ docker-compose.yml            # Main compose configuration
```

## Detailed Structure

### ğŸ“ src/ - Core Application
```
src/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ etl/                            # ETL business logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extract.py                  # Data extraction functions
â”‚   â”œâ”€â”€ transform.py                # Data transformation functions
â”‚   â””â”€â”€ load.py                     # Data loading functions
â”œâ”€â”€ streaming/                      # Kafka streaming components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ producers.py                # Kafka producers
â”‚   â””â”€â”€ connectors/                 # Kafka connectors
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ spark/                          # Spark ETL jobs
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                   # Spark configuration
â”‚   â””â”€â”€ jobs/                       # Spark job definitions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ batch_etl.py            # Main batch ETL job
â”‚       â””â”€â”€ notebooks/              # Databricks notebooks
â”œâ”€â”€ dbt/                            # dbt transformations
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ macros/
â”‚   â””â”€â”€ tests/
â””â”€â”€ utils/                          # Shared utilities and helpers
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config_validator.py         # Configuration validation
    â”œâ”€â”€ config_templates.py         # Configuration templates
    â””â”€â”€ setup_doctor.py             # Setup and health checks
```

### ğŸ“ orchestration/ - Workflow Management
```
orchestration/
â”œâ”€â”€ airflow/                        # Airflow components
â”‚   â”œâ”€â”€ dags/                       # DAG definitions
â”‚   â”‚   â”œâ”€â”€ sales_data_pipeline_dag.py
â”‚   â”‚   â”œâ”€â”€ cloud_sales_pipeline_dag.py
â”‚   â”‚   â”œâ”€â”€ maintenance_dag.py
â”‚   â”‚   â””â”€â”€ pipeline_monitoring_dag.py
â”‚   â”œâ”€â”€ plugins/                    # Custom plugins
â”‚   â”œâ”€â”€ logs/                       # Airflow logs
â”‚   â””â”€â”€ postgres/                   # Postgres data
â””â”€â”€ scripts/                        # PostgreSQL Pipeline scripts
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ postgres_preflight_check.py
    â”œâ”€â”€ postgres_create_tables.py
    â”œâ”€â”€ postgres_transform.py
    â”œâ”€â”€ postgres_load.py
    â””â”€â”€ postgres_upload_data.py
```

### ğŸ“ infrastructure/ - Infrastructure as Code
```
infrastructure/
â”œâ”€â”€ terraform/                      # Terraform configurations
â”‚   â”œâ”€â”€ modules/                    # Reusable Terraform modules
â”‚   â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ network/
â”‚   â”‚   â””â”€â”€ iam/
â”‚   â””â”€â”€ environments/               # Environment-specific configs
â”œâ”€â”€ docker/                         # Docker configurations
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â””â”€â”€ Dockerfile-airflow
â”‚   â””â”€â”€ etl/
â”‚       â””â”€â”€ Dockerfile
â””â”€â”€ deployment/                     # Deployment scripts and configs
    â””â”€â”€ scripts/
```

### ğŸ“ tests/ - Unified Testing Framework
```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py                     # Shared pytest configuration
â”œâ”€â”€ unit/                           # Unit tests organized by module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_spark/                 # Spark unit tests
â”‚   â”œâ”€â”€ test_streaming/             # Streaming unit tests
â”‚   â”œâ”€â”€ test_spark/                 # Spark unit tests
â”‚   â”œâ”€â”€ test_dbt/                   # dbt unit tests
â”‚   â””â”€â”€ test_airflow/               # Airflow unit tests
â”œâ”€â”€ integration/                    # Integration tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_e2e_pipeline.py
â”‚   â”œâ”€â”€ data_validators.py
â”‚   â”œâ”€â”€ infrastructure_manager.py
â”‚   â””â”€â”€ performance_monitor.py
â”œâ”€â”€ e2e/                           # End-to-end tests
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ performance/                    # Performance tests
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ fixtures/                       # Test fixtures and data
â””â”€â”€ utils/                          # Testing utilities
```

### ğŸ“ config/ - Configuration Management
```
config/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ environments/                   # Environment-specific configs
â”œâ”€â”€ platforms/                      # Platform-specific configs
â”‚   â”œâ”€â”€ aws/
â”‚   â”œâ”€â”€ gcp/
â”‚   â””â”€â”€ azure/
â””â”€â”€ templates/                      # Configuration templates
```

### ğŸ“ docs/ - Documentation
```
docs/
â”œâ”€â”€ README.md                       # Documentation overview
â”œâ”€â”€ architecture/                   # System architecture docs
â”‚   â”œâ”€â”€ snowflake.md
â”‚   â””â”€â”€ streaming.md
â”œâ”€â”€ deployment/                     # Deployment guides
â”‚   â””â”€â”€ cloud-deployment.md
â”œâ”€â”€ development/                    # Development guides
â”‚   â”œâ”€â”€ TESTING_GUIDE.md
â”‚   â”œâ”€â”€ CONFIG_VALIDATOR_README.md
â”‚   â””â”€â”€ KAFKA_PRODUCER_TESTS_SUMMARY.md
â”œâ”€â”€ api/                           # API documentation
â””â”€â”€ troubleshooting/               # Troubleshooting guides
```

### ğŸ“ tools/ - Development Tools
```
tools/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ testing/                        # Testing tools and runners
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ run_tests.py                # Main test runner
â”‚   â””â”€â”€ test_runners/
â”œâ”€â”€ validation/                     # Validation tools
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ demo_config_validator.py
â””â”€â”€ monitoring/                     # Monitoring tools
    â””â”€â”€ __init__.py
```

### ğŸ“ requirements/ - Dependency Management
```
requirements/
â”œâ”€â”€ base.txt                        # Core dependencies
â”œâ”€â”€ dev.txt                         # Development dependencies
â”œâ”€â”€ test.txt                        # Testing dependencies
â”œâ”€â”€ cloud.txt                       # Cloud-specific dependencies
â””â”€â”€ validation.txt                  # Validation tool dependencies
```

## Key Changes Made

### 1. **Root Directory Cleanup**
- Moved utility files from root to appropriate modules
- Only essential files remain at root level
- Created modern `pyproject.toml` configuration

### 2. **Source Code Organization**
- Renamed files to follow Python conventions (`extract.py` vs `extract_funcs.py`)
- Organized by business domain (ETL, streaming, spark, etc.)
- Created proper package structure with `__init__.py` files

### 3. **Testing Consolidation**
- Unified all tests under single `tests/` directory
- Organized by test type (unit, integration, e2e, performance)
- Proper pytest configuration and fixtures

### 4. **Infrastructure Organization**
- Separated infrastructure code from application code
- Organized Docker files by service
- Grouped deployment scripts and configurations

### 5. **Configuration Management**
- Centralized all configuration files
- Organized by environment and platform
- Created template system for easy setup

### 6. **Documentation Structure**
- Consolidated all documentation under `docs/`
- Organized by purpose (architecture, deployment, development)
- Created clear navigation structure

## Import Changes

Key import changes made during reorganization:

```python
# OLD
from etl.extract_funcs import get_data_files
from etl.transform_funcs import process_sales_data
from etl.load_funcs import load_to_postgres

# NEW
from src.etl.extract import get_data_files
from src.etl.transform import process_sales_data
from src.etl.load import load_to_postgres
```

```python
# OLD
from kafka_producer import SalesDataProducer

# NEW
from src.streaming.producers import SalesDataProducer
```

```python
# OLD
from sales_batch_job import SalesETLJob

# NEW
from src.spark.jobs.batch_etl import SalesETLJob
```

## Benefits of New Structure

1. **Professional Organization**: Follows Python packaging best practices
2. **Clear Separation of Concerns**: Each directory has a single responsibility
3. **Scalable Structure**: Easy to add new components without cluttering
4. **Better Testing**: Unified testing framework with clear organization
5. **Improved Documentation**: Consolidated and well-organized docs
6. **Modern Configuration**: Uses `pyproject.toml` and proper dependency management
7. **Infrastructure as Code**: Clear separation of infrastructure concerns
8. **Development Tools**: Dedicated space for development utilities

This structure provides a solid foundation for enterprise-scale development while maintaining clarity and ease of navigation.
